{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2d5b461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50b6f365",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CameraCalibration():\n",
    "    \"\"\" Class that calibrate camera using chessboard images.\n",
    "\n",
    "    Attributes:\n",
    "        mtx (np.array): Camera matrix \n",
    "        dist (np.array): Distortion coefficients\n",
    "    \"\"\"\n",
    "    def __init__(self, image_dir, nx, ny, debug=False):\n",
    "        \"\"\" Init CameraCalibration.\n",
    "\n",
    "        Parameters:\n",
    "            image_dir (str): path to folder contains chessboard images\n",
    "            nx (int): width of chessboard (number of squares)\n",
    "            ny (int): height of chessboard (number of squares)\n",
    "        \"\"\"\n",
    "        fnames = glob.glob(\"{}/*\".format(image_dir))\n",
    "        objpoints = []\n",
    "        imgpoints = []\n",
    "        \n",
    "        # Coordinates of chessboard's corners in 3D\n",
    "        objp = np.zeros((nx*ny, 3), np.float32)\n",
    "        objp[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1, 2)\n",
    "        \n",
    "        # Go through all chessboard images\n",
    "        for f in fnames:\n",
    "            img = mpimg.imread(f)\n",
    "\n",
    "            # Convert to grayscale image\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "            # Find chessboard corners\n",
    "            ret, corners = cv2.findChessboardCorners(img, (nx, ny))\n",
    "            if ret:\n",
    "                imgpoints.append(corners)\n",
    "                objpoints.append(objp)\n",
    "\n",
    "        shape = (img.shape[1], img.shape[0])\n",
    "        ret, self.mtx, self.dist, _, _ = cv2.calibrateCamera(objpoints, imgpoints, shape, None, None)\n",
    "\n",
    "        if not ret:\n",
    "            raise Exception(\"Unable to calibrate camera\")\n",
    "\n",
    "    def undistort(self, img):\n",
    "        \"\"\" Return undistort image.\n",
    "\n",
    "        Parameters:\n",
    "            img (np.array): Input image\n",
    "\n",
    "        Returns:\n",
    "            Image (np.array): Undistorted image\n",
    "        \"\"\"\n",
    "        # Convert to grayscale image\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        return cv2.undistort(img, self.mtx, self.dist, None, self.mtx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af7842af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerspectiveTransformation:\n",
    "    \"\"\" This a class for transforming image between front view and top view\n",
    "\n",
    "    Attributes:\n",
    "        src (np.array): Coordinates of 4 source points\n",
    "        dst (np.array): Coordinates of 4 destination points\n",
    "        M (np.array): Matrix to transform image from front view to top view\n",
    "        M_inv (np.array): Matrix to transform image from top view to front view\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Init PerspectiveTransformation.\"\"\"\n",
    "        self.src = np.float32([(550, 460),     # top-left\n",
    "                               (150, 720),     # bottom-left\n",
    "                               (1200, 720),    # bottom-right\n",
    "                               (770, 460)])    # top-right\n",
    "        self.dst = np.float32([(100, 0),\n",
    "                               (100, 720),\n",
    "                               (1100, 720),\n",
    "                               (1100, 0)])\n",
    "        self.M = cv2.getPerspectiveTransform(self.src, self.dst)\n",
    "        self.M_inv = cv2.getPerspectiveTransform(self.dst, self.src)\n",
    "\n",
    "    def forward(self, img, img_size=(1280, 720), flags=cv2.INTER_LINEAR):\n",
    "        \"\"\" Take a front view image and transform to top view\n",
    "\n",
    "        Parameters:\n",
    "            img (np.array): A front view image\n",
    "            img_size (tuple): Size of the image (width, height)\n",
    "            flags : flag to use in cv2.warpPerspective()\n",
    "\n",
    "        Returns:\n",
    "            Image (np.array): Top view image\n",
    "        \"\"\"\n",
    "        return cv2.warpPerspective(img, self.M, img_size, flags=flags)\n",
    "\n",
    "    def backward(self, img, img_size=(1280, 720), flags=cv2.INTER_LINEAR):\n",
    "        \"\"\" Take a top view image and transform it to front view\n",
    "\n",
    "        Parameters:\n",
    "            img (np.array): A top view image\n",
    "            img_size (tuple): Size of the image (width, height)\n",
    "            flags (int): flag to use in cv2.warpPerspective()\n",
    "\n",
    "        Returns:\n",
    "            Image (np.array): Front view image\n",
    "        \"\"\"\n",
    "        return cv2.warpPerspective(img, self.M_inv, img_size, flags=flags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2606ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_rel(img, lo, hi):\n",
    "    vmin = np.min(img)\n",
    "    vmax = np.max(img)\n",
    "    \n",
    "    vlo = vmin + (vmax - vmin) * lo\n",
    "    vhi = vmin + (vmax - vmin) * hi\n",
    "    return np.uint8((img >= vlo) & (img <= vhi)) * 255\n",
    "\n",
    "def threshold_abs(img, lo, hi):\n",
    "    return np.uint8((img >= lo) & (img <= hi)) * 255\n",
    "\n",
    "class Thresholding:\n",
    "    \"\"\" This class is for extracting relevant pixels in an image.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\" Init Thresholding.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def forward(self, img):\n",
    "        \"\"\" Take an image and extract all relavant pixels.\n",
    "\n",
    "        Parameters:\n",
    "            img (np.array): Input image\n",
    "\n",
    "        Returns:\n",
    "            binary (np.array): A binary image represent all positions of relavant pixels.\n",
    "        \"\"\"\n",
    "        hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        h_channel = hls[:,:,0]\n",
    "        l_channel = hls[:,:,1]\n",
    "        s_channel = hls[:,:,2]\n",
    "        v_channel = hsv[:,:,2]\n",
    "\n",
    "        right_lane = threshold_rel(l_channel, 0.8, 1.0)\n",
    "        right_lane[:,:750] = 0\n",
    "\n",
    "        left_lane = threshold_abs(h_channel, 20, 30)\n",
    "        left_lane &= threshold_rel(v_channel, 0.7, 1.0)\n",
    "        left_lane[:,550:] = 0\n",
    "\n",
    "        img2 = left_lane | right_lane\n",
    "\n",
    "        return img2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5cc62bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist(img):\n",
    "    bottom_half = img[img.shape[0]//2:,:]\n",
    "    return np.sum(bottom_half, axis=0)\n",
    "\n",
    "class LaneLines:\n",
    "    \"\"\" Class containing information about detected lane lines.\n",
    "\n",
    "    Attributes:\n",
    "        left_fit (np.array): Coefficients of a polynomial that fit left lane line\n",
    "        right_fit (np.array): Coefficients of a polynomial that fit right lane line\n",
    "        parameters (dict): Dictionary containing all parameters needed for the pipeline\n",
    "        debug (boolean): Flag for debug/normal mode\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Init Lanelines.\n",
    "\n",
    "        Parameters:\n",
    "            left_fit (np.array): Coefficients of polynomial that fit left lane\n",
    "            right_fit (np.array): Coefficients of polynomial that fit right lane\n",
    "            binary (np.array): binary image\n",
    "        \"\"\"\n",
    "        self.left_fit = None\n",
    "        self.right_fit =None\n",
    "        self.binary = None\n",
    "        self.nonzero = None\n",
    "        self.nonzerox = None\n",
    "        self.nonzeroy = None\n",
    "        self.clear_visibility = True\n",
    "        self.dir = []\n",
    "        self.left_curve_img = mpimg.imread('left_turn.png')\n",
    "        self.right_curve_img = mpimg.imread('right_turn.png')\n",
    "        self.keep_straight_img = mpimg.imread('straight.png')\n",
    "        self.left_curve_img = cv2.normalize(src=self.left_curve_img, dst=None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "        self.right_curve_img = cv2.normalize(src=self.right_curve_img, dst=None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "        self.keep_straight_img = cv2.normalize(src=self.keep_straight_img, dst=None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "\n",
    "        # HYPERPARAMETERS\n",
    "        # Number of sliding windows\n",
    "        self.nwindows = 9\n",
    "        # Width of the the windows +/- margin\n",
    "        self.margin = 100\n",
    "        # Mininum number of pixels found to recenter window\n",
    "        self.minpix = 50\n",
    "\n",
    "    def forward(self, img):\n",
    "        \"\"\"Take a image and detect lane lines.\n",
    "\n",
    "        Parameters:\n",
    "            img (np.array): An binary image containing relevant pixels\n",
    "\n",
    "        Returns:\n",
    "            Image (np.array): An RGB image containing lane lines pixels and other details\n",
    "        \"\"\"\n",
    "        self.extract_features(img)\n",
    "        return self.fit_poly(img)\n",
    "\n",
    "    def pixels_in_window(self, center, margin, height):\n",
    "        \"\"\" Return all pixel that in a specific window\n",
    "\n",
    "        Parameters:\n",
    "            center (tuple): coordinate of the center of the window\n",
    "            margin (int): half width of the window\n",
    "            height (int): height of the window\n",
    "\n",
    "        Returns:\n",
    "            pixelx (np.array): x coordinates of pixels that lie inside the window\n",
    "            pixely (np.array): y coordinates of pixels that lie inside the window\n",
    "        \"\"\"\n",
    "        topleft = (center[0]-margin, center[1]-height//2)\n",
    "        bottomright = (center[0]+margin, center[1]+height//2)\n",
    "\n",
    "        condx = (topleft[0] <= self.nonzerox) & (self.nonzerox <= bottomright[0])\n",
    "        condy = (topleft[1] <= self.nonzeroy) & (self.nonzeroy <= bottomright[1])\n",
    "        return self.nonzerox[condx&condy], self.nonzeroy[condx&condy]\n",
    "\n",
    "    def extract_features(self, img):\n",
    "        \"\"\" Extract features from a binary image\n",
    "\n",
    "        Parameters:\n",
    "            img (np.array): A binary image\n",
    "        \"\"\"\n",
    "        self.img = img\n",
    "        # Height of of windows - based on nwindows and image shape\n",
    "        self.window_height = np.int(img.shape[0]//self.nwindows)\n",
    "\n",
    "        # Identify the x and y positions of all nonzero pixel in the image\n",
    "        self.nonzero = img.nonzero()\n",
    "        self.nonzerox = np.array(self.nonzero[1])\n",
    "        self.nonzeroy = np.array(self.nonzero[0])\n",
    "\n",
    "    def find_lane_pixels(self, img):\n",
    "        \"\"\"Find lane pixels from a binary warped image.\n",
    "\n",
    "        Parameters:\n",
    "            img (np.array): A binary warped image\n",
    "\n",
    "        Returns:\n",
    "            leftx (np.array): x coordinates of left lane pixels\n",
    "            lefty (np.array): y coordinates of left lane pixels\n",
    "            rightx (np.array): x coordinates of right lane pixels\n",
    "            righty (np.array): y coordinates of right lane pixels\n",
    "            out_img (np.array): A RGB image that use to display result later on.\n",
    "        \"\"\"\n",
    "        assert(len(img.shape) == 2)\n",
    "\n",
    "        # Create an output image to draw on and visualize the result\n",
    "        out_img = np.dstack((img, img, img))\n",
    "\n",
    "        histogram = hist(img)\n",
    "        midpoint = histogram.shape[0]//2\n",
    "        leftx_base = np.argmax(histogram[:midpoint])\n",
    "        rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "        # Current position to be update later for each window in nwindows\n",
    "        leftx_current = leftx_base\n",
    "        rightx_current = rightx_base\n",
    "        y_current = img.shape[0] + self.window_height//2\n",
    "\n",
    "        # Create empty lists to reveice left and right lane pixel\n",
    "        leftx, lefty, rightx, righty = [], [], [], []\n",
    "\n",
    "        # Step through the windows one by one\n",
    "        for _ in range(self.nwindows):\n",
    "            y_current -= self.window_height\n",
    "            center_left = (leftx_current, y_current)\n",
    "            center_right = (rightx_current, y_current)\n",
    "\n",
    "            good_left_x, good_left_y = self.pixels_in_window(center_left, self.margin, self.window_height)\n",
    "            good_right_x, good_right_y = self.pixels_in_window(center_right, self.margin, self.window_height)\n",
    "\n",
    "            # Append these indices to the lists\n",
    "            leftx.extend(good_left_x)\n",
    "            lefty.extend(good_left_y)\n",
    "            rightx.extend(good_right_x)\n",
    "            righty.extend(good_right_y)\n",
    "\n",
    "            if len(good_left_x) > self.minpix:\n",
    "                leftx_current = np.int32(np.mean(good_left_x))\n",
    "            if len(good_right_x) > self.minpix:\n",
    "                rightx_current = np.int32(np.mean(good_right_x))\n",
    "\n",
    "        return leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "    def fit_poly(self, img):\n",
    "        \"\"\"Find the lane line from an image and draw it.\n",
    "\n",
    "        Parameters:\n",
    "            img (np.array): a binary warped image\n",
    "\n",
    "        Returns:\n",
    "            out_img (np.array): a RGB image that have lane line drawn on that.\n",
    "        \"\"\"\n",
    "\n",
    "        leftx, lefty, rightx, righty, out_img = self.find_lane_pixels(img)\n",
    "        if len(lefty) > 1500:\n",
    "            self.left_fit = np.polyfit(lefty, leftx, 2)\n",
    "        if len(righty) > 1500:\n",
    "            self.right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "        # Generate x and y values for plotting\n",
    "        maxy = img.shape[0] - 1\n",
    "        miny = img.shape[0] // 3\n",
    "        if len(lefty):\n",
    "            maxy = max(maxy, np.max(lefty))\n",
    "            miny = min(miny, np.min(lefty))\n",
    "\n",
    "        if len(righty):\n",
    "            maxy = max(maxy, np.max(righty))\n",
    "            miny = min(miny, np.min(righty))\n",
    "\n",
    "        ploty = np.linspace(miny, maxy, img.shape[0])\n",
    "        left_fitx = self.left_fit[0]*ploty**2 + self.left_fit[1]*ploty + self.left_fit[2]\n",
    "        right_fitx = self.right_fit[0]*ploty**2 + self.right_fit[1]*ploty + self.right_fit[2]\n",
    "\n",
    "        # Visualization\n",
    "        for i, y in enumerate(ploty):\n",
    "            l = int(left_fitx[i])\n",
    "            r = int(right_fitx[i])\n",
    "            y = int(y)\n",
    "            cv2.line(out_img, (l, y), (r, y), (0, 255, 0))\n",
    "\n",
    "        lR, rR, pos = self.measure_curvature()\n",
    "\n",
    "        return out_img\n",
    "\n",
    "    def plot(self, out_img):\n",
    "        np.set_printoptions(precision=6, suppress=True)\n",
    "        lR, rR, pos = self.measure_curvature()\n",
    "\n",
    "        value = None\n",
    "        if abs(self.left_fit[0]) > abs(self.right_fit[0]):\n",
    "            value = self.left_fit[0]\n",
    "        else:\n",
    "            value = self.right_fit[0]\n",
    "\n",
    "        if abs(value) <= 0.00015:\n",
    "            self.dir.append('F')\n",
    "        elif value < 0:\n",
    "            self.dir.append('L')\n",
    "        else:\n",
    "            self.dir.append('R')\n",
    "        \n",
    "        if len(self.dir) > 10:\n",
    "            self.dir.pop(0)\n",
    "\n",
    "        W = 400\n",
    "        H = 500\n",
    "        widget = np.copy(out_img[:H, :W])\n",
    "        widget //= 2\n",
    "        widget[0,:] = [0, 0, 255]\n",
    "        widget[-1,:] = [0, 0, 255]\n",
    "        widget[:,0] = [0, 0, 255]\n",
    "        widget[:,-1] = [0, 0, 255]\n",
    "        out_img[:H, :W] = widget\n",
    "\n",
    "        direction = max(set(self.dir), key = self.dir.count)\n",
    "        msg = \"Keep Straight Ahead\"\n",
    "        curvature_msg = \"Curvature = {:.0f} m\".format(min(lR, rR))\n",
    "        if direction == 'L':\n",
    "            y, x = self.left_curve_img[:,:,3].nonzero()\n",
    "            out_img[y, x-100+W//2] = self.left_curve_img[y, x, :3]\n",
    "            msg = \"Left Curve Ahead\"\n",
    "        if direction == 'R':\n",
    "            y, x = self.right_curve_img[:,:,3].nonzero()\n",
    "            out_img[y, x-100+W//2] = self.right_curve_img[y, x, :3]\n",
    "            msg = \"Right Curve Ahead\"\n",
    "        if direction == 'F':\n",
    "            y, x = self.keep_straight_img[:,:,3].nonzero()\n",
    "            out_img[y, x-100+W//2] = self.keep_straight_img[y, x, :3]\n",
    "\n",
    "        cv2.putText(out_img, msg, org=(10, 240), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(255, 255, 255), thickness=2)\n",
    "        if direction in 'LR':\n",
    "            cv2.putText(out_img, curvature_msg, org=(10, 280), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(255, 255, 255), thickness=2)\n",
    "\n",
    "        cv2.putText(\n",
    "            out_img,\n",
    "            \"Good Lane Keeping\",\n",
    "            org=(10, 400),\n",
    "            fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            fontScale=1.2,\n",
    "            color=(0, 255, 0),\n",
    "            thickness=2)\n",
    "\n",
    "        cv2.putText(\n",
    "            out_img,\n",
    "            \"Vehicle is {:.2f} m away from center\".format(pos),\n",
    "            org=(10, 450),\n",
    "            fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            fontScale=0.66,\n",
    "            color=(255, 255, 255),\n",
    "            thickness=2)\n",
    "\n",
    "        return out_img\n",
    "\n",
    "    def measure_curvature(self):\n",
    "        ym = 30/720\n",
    "        xm = 3.7/700\n",
    "\n",
    "        left_fit = self.left_fit.copy()\n",
    "        right_fit = self.right_fit.copy()\n",
    "        y_eval = 700 * ym\n",
    "\n",
    "        # Compute R_curve (radius of curvature)\n",
    "        left_curveR =  ((1 + (2*left_fit[0] *y_eval + left_fit[1])**2)**1.5)  / np.absolute(2*left_fit[0])\n",
    "        right_curveR = ((1 + (2*right_fit[0]*y_eval + right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0])\n",
    "\n",
    "        xl = np.dot(self.left_fit, [700**2, 700, 1])\n",
    "        xr = np.dot(self.right_fit, [700**2, 700, 1])\n",
    "        pos = (1280//2 - (xl+xr)//2)*xm\n",
    "        return left_curveR, right_curveR, pos \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5d9e0902",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docopt import docopt\n",
    "from IPython.display import HTML, Video\n",
    "from moviepy.editor import VideoFileClip\n",
    "#from CameraCalibration import CameraCalibration\n",
    "#from Thresholding import *\n",
    "#from PerspectiveTransformation import *\n",
    "#from LaneLines import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "196ff68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-836f278b5a43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-45-836f278b5a43>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mfindLaneLines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFindLaneLines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'video'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mfindLaneLines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_video\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mfindLaneLines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-45-836f278b5a43>\u001b[0m in \u001b[0;36mprocess_video\u001b[1;34m(self, input_path)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mprocess_video\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mclip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVideoFileClip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mout_clip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfl_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0mout_clip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_videofile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test_op.mp4\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maudio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\moviepy\\video\\VideoClip.py\u001b[0m in \u001b[0;36mfl_image\u001b[1;34m(self, image_func, apply_to)\u001b[0m\n\u001b[0;32m    488\u001b[0m         \"\"\"\n\u001b[0;32m    489\u001b[0m         \u001b[0mapply_to\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapply_to\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 490\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mgf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mimage_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m     \u001b[1;31m# --------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\moviepy\\Clip.py\u001b[0m in \u001b[0;36mfl\u001b[1;34m(self, fun, apply_to, keep_duration)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[1;31m#mf = copy(self.make_frame)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m         \u001b[0mnewclip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_make_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-178>\u001b[0m in \u001b[0;36mset_make_frame\u001b[1;34m(self, mf)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\moviepy\\decorators.py\u001b[0m in \u001b[0;36moutplace\u001b[1;34m(f, clip, *a, **k)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;34m\"\"\" Applies f(clip.copy(), *a, **k) and returns clip.copy()\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mnewclip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewclip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnewclip\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\moviepy\\video\\VideoClip.py\u001b[0m in \u001b[0;36mset_make_frame\u001b[1;34m(self, mf)\u001b[0m\n\u001b[0;32m    642\u001b[0m         \"\"\"\n\u001b[0;32m    643\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0moutplace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-128>\u001b[0m in \u001b[0;36mget_frame\u001b[1;34m(self, t)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\moviepy\\decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(f, *a, **kw)\u001b[0m\n\u001b[0;32m     87\u001b[0m         new_kw = {k: fun(v) if k in varnames else v\n\u001b[0;32m     88\u001b[0m                  for (k,v) in kw.items()}\n\u001b[1;32m---> 89\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnew_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mnew_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\moviepy\\Clip.py\u001b[0m in \u001b[0;36mget_frame\u001b[1;34m(self, t)\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\moviepy\\Clip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[1;31m#mf = copy(self.make_frame)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m         \u001b[0mnewclip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_make_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\moviepy\\video\\VideoClip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(gf, t)\u001b[0m\n\u001b[0;32m    488\u001b[0m         \"\"\"\n\u001b[0;32m    489\u001b[0m         \u001b[0mapply_to\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapply_to\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 490\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mgf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mimage_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m     \u001b[1;31m# --------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-45-836f278b5a43>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthresholding\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlanelines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-ca71e88fce9c>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     53\u001b[0m         \"\"\"\n\u001b[0;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_poly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpixels_in_window\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcenter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-ca71e88fce9c>\u001b[0m in \u001b[0;36mfit_poly\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[0mploty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m         \u001b[0mleft_fitx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft_fit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mploty\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft_fit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mploty\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft_fit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[0mright_fitx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_fit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mploty\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_fit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mploty\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_fit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "class FindLaneLines:\n",
    "    \"\"\" This class is for parameter tunning.\n",
    "\n",
    "    Attributes:\n",
    "        ...\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\" Init Application\"\"\"\n",
    "        self.calibration = CameraCalibration('camera_cal', 9, 6)\n",
    "        self.thresholding = Thresholding()\n",
    "        self.transform = PerspectiveTransformation()\n",
    "        self.lanelines = LaneLines()\n",
    "\n",
    "    def forward(self, img):\n",
    "        out_img = np.copy(img)\n",
    "        img = self.calibration.undistort(img)\n",
    "        img = self.transform.forward(img)\n",
    "        img = self.thresholding.forward(img)\n",
    "        img = self.lanelines.forward(img)\n",
    "        img = self.transform.backward(img)\n",
    "\n",
    "        out_img = cv2.addWeighted(out_img, 1, img, 0.6, 0)\n",
    "        out_img = self.lanelines.plot(out_img)\n",
    "        return out_img\n",
    "\n",
    "    def process_image(self, input_path):\n",
    "        img = mpimg.imread(input_path)\n",
    "        out_img = self.forward(img)\n",
    "        cv2.imshow(\"Result Image\",out_img)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "    def process_video(self, input_path):\n",
    "        clip = VideoFileClip(input_path)\n",
    "        out_clip = clip.fl_image(self.forward)\n",
    "        out_clip.write_videofile(\"test_op.mp4\", audio=False)\n",
    "\n",
    "def main():\n",
    "    type = 'video'\n",
    "    input = \"test1.mp4\"\n",
    "    findLaneLines = FindLaneLines()\n",
    "    if type == 'video':\n",
    "        findLaneLines.process_video(input)\n",
    "    else:\n",
    "        findLaneLines.process_image(input)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eebbb51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
